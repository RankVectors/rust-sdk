/*
 * RankVectors API
 *
 * Intelligent internal linking optimization API using AI.   RankVectors helps you automatically discover and implement optimal internal links  across your website to improve SEO performance and user experience.  ## Key Features - **AI-Powered Analysis**: Uses OpenAI embeddings to find optimal linking opportunities - **Smart Crawling**: Automatically crawls and analyzes your website content - **Automated Implementation**: Implement links via webhooks or manual instructions - **Page-Based Plans**: Predictable pricing by number of pages monitored - **Multi-Platform Support**: Works with any CMS or platform via REST API  ## Getting Started 1. Create a project with your website URL 2. Start a crawl to analyze your content 3. Generate AI-powered link suggestions 4. Implement suggestions via API or webhook 5. Track performance and manage page usage and limits  ## Authentication Most API endpoints support authentication using your RankVectors API key. Include your API key in the `Authorization` header: ``` Authorization: Bearer YOUR_API_KEY ```  Get your API key from your RankVectors dashboard: Settings â†’ API Keys  **Note**: Some endpoints (marked in the documentation) support both API key authentication and web session authentication (Stack Auth).  API key authentication is required for SDK usage and external integrations like WordPress plugins. 
 *
 * The version of the OpenAPI document: 1.3.1
 * Contact: tj@rankvectors.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct Crawl {
    /// Unique crawl identifier
    #[serde(rename = "id")]
    pub id: String,
    /// Project identifier
    #[serde(rename = "projectId")]
    pub project_id: String,
    /// Crawl status
    #[serde(rename = "status")]
    pub status: Status,
    /// Crawl start timestamp
    #[serde(rename = "startedAt")]
    pub started_at: String,
    /// Crawl completion timestamp
    #[serde(rename = "completedAt", skip_serializing_if = "Option::is_none")]
    pub completed_at: Option<String>,
    /// Number of pages crawled
    #[serde(rename = "pagesCrawled", skip_serializing_if = "Option::is_none")]
    pub pages_crawled: Option<i32>,
    /// Error message if crawl failed
    #[serde(rename = "errorMessage", skip_serializing_if = "Option::is_none")]
    pub error_message: Option<String>,
}

impl Crawl {
    pub fn new(id: String, project_id: String, status: Status, started_at: String) -> Crawl {
        Crawl {
            id,
            project_id,
            status,
            started_at,
            completed_at: None,
            pages_crawled: None,
            error_message: None,
        }
    }
}
/// Crawl status
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Status {
    #[serde(rename = "pending")]
    Pending,
    #[serde(rename = "in_progress")]
    InProgress,
    #[serde(rename = "completed")]
    Completed,
    #[serde(rename = "failed")]
    Failed,
}

impl Default for Status {
    fn default() -> Status {
        Self::Pending
    }
}

